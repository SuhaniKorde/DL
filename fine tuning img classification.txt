import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.datasets import cifar10
from tensorflow.keras.utils import to_categorical
import matplotlib.pyplot as plt
import numpy as np

# Load and preprocess CIFAR-10 dataset
(x_train, y_train), (x_test, y_test) = cifar10.load_data()
x_train, x_test = x_train.astype("float32") / 255.0, x_test.astype("float32") / 255.0
y_train, y_test = to_categorical(y_train, 10), to_categorical(y_test, 10)

# Resize images to match MobileNetV2 input size
IMG_SIZE = 64
def resize_batch(x, size=IMG_SIZE):
    return tf.image.resize(x, (size, size)).numpy()

x_train_r, x_test_r = resize_batch(x_train), resize_batch(x_test)

# Load pretrained MobileNetV2 base model
base = tf.keras.applications.MobileNetV2(weights='imagenet', include_top=False,
                                         input_shape=(IMG_SIZE, IMG_SIZE, 3))
base.trainable = False

# Add custom classification layers on top
model = models.Sequential([
    base,
    layers.GlobalAveragePooling2D(),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.3),
    layers.Dense(10, activation='softmax')
])

# Compile and train (feature extraction stage)
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
history = model.fit(x_train_r, y_train, epochs=3, batch_size=64, validation_split=0.1, verbose=2)

# Fine-tuning: unfreeze last few layers of base model
base.trainable = True
for layer in base.layers[:-40]:
    layer.trainable = False

# Re-compile with smaller learning rate and train again
model.compile(optimizer=tf.keras.optimizers.Adam(1e-4),
              loss='categorical_crossentropy', metrics=['accuracy'])
history2 = model.fit(x_train_r, y_train, epochs=2, batch_size=64, validation_split=0.1, verbose=2)

# Evaluate model on test data
loss, acc = model.evaluate(x_test_r, y_test, verbose=0)
print(f"Test accuracy (fine-tuned): {acc:.4f}")

# Show sample training images
for i in range(9):
    plt.subplot(3,3,i+1)
    plt.imshow(x_train[i])
    plt.title(np.argmax(y_train[i]))
    plt.axis('off')
plt.show()

# Plot training and validation accuracy
plt.plot(history.history['accuracy'], label='train_acc')
plt.plot(history.history['val_accuracy'], label='val_acc')
plt.legend()
plt.title('Training vs Validation Accuracy')
plt.show()
